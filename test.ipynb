{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "232d3094-6b5b-44ba-9732-0d723a85f9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No folder found for prefix 'InboundShipments'\n",
      "Loaded Topocean file successfully!\n",
      "Loaded OEC_Email file successfully!\n",
      "Loaded OEC_Portal file successfully!\n",
      "No folder found for prefix 'PTP SOMA'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SilviaJulianaNavasPi\\anaconda3\\envs\\.seleniumvenv\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded TaneraGo file successfully!\n",
      "Loaded Harbour file successfully!\n",
      "Loaded Idc file successfully!\n",
      "Loaded workbook: Inbound Weekly Update Template02Harbour.xlsm\n",
      "Closing extra workbook: Book1\n",
      "Warning: DataFrame for 'ERP' is None, skipping.\n",
      "Pasted data into sheet: topocean\n",
      "Pasted data into sheet: OEC Portal\n",
      "Pasted data into sheet: OEC Email\n",
      "Warning: DataFrame for 'Soma' is None, skipping.\n",
      "Pasted data into sheet: Tanera Go\n",
      "Pasted data into sheet: Harbour\n",
      "Pasted data into sheet: IDC\n",
      "Workbook saved as: Inbound Weekly Update Template LMH 06.09.25.xlsm in C:\\Users\\SilviaJulianaNavasPi/OneDrive - Prime Time Packaging/Inbound Update\n",
      "Workbook closed.\n",
      "Excel app quit.\n",
      "\n",
      "Script executed in 5.95 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import glob\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "import xlwings as xw\n",
    "from datetime import datetime\n",
    "import os\n",
    "from find_latest_folders import get_latest_folders\n",
    "\n",
    "\n",
    "# Functions\n",
    "ERP_df = None\n",
    "Topocean_df = None\n",
    "OEC_Portal_df = None\n",
    "OEC_Email_df = None\n",
    "Soma_df = None\n",
    "TaneraGo_df = None\n",
    "Harbour_df = None\n",
    "Idc_df = None\n",
    "\n",
    "# File Pattern Recognition\n",
    "def load_file_from_config(config, folder_path):\n",
    "    # Handle both \"extensions\" and \"extension\"/\"loader\" format\n",
    "    if \"extensions\" in config:\n",
    "        ext_loader_pairs = config[\"extensions\"]\n",
    "    elif \"extension\" in config and \"loader\" in config:\n",
    "        extensions = config[\"extension\"]\n",
    "        if isinstance(extensions, str):\n",
    "            extensions = [extensions]\n",
    "        ext_loader_pairs = [(ext, config[\"loader\"]) for ext in extensions]\n",
    "    else:\n",
    "        raise KeyError(\"Missing required keys: 'extensions' or 'extension' with 'loader'\")\n",
    "\n",
    "    for ext, loader in ext_loader_pairs:\n",
    "        pattern = os.path.join(folder_path, f\"{config['prefix']}*.{ext}\")\n",
    "        matching_files = glob.glob(pattern)\n",
    "        if matching_files:\n",
    "            file_path = matching_files[0]\n",
    "            try:\n",
    "                df = loader(file_path, **config.get(\"kwargs\", {}))\n",
    "                if \"postprocess\" in config:\n",
    "                    df = config[\"postprocess\"](df)\n",
    "                return df\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file_path}: {e}\")\n",
    "                return None\n",
    "    return None\n",
    "    \n",
    "# OEC Portal Data Cleaning    \n",
    "def clean_oec_portal(df):\n",
    "    # Convert columns 8 to 10 (i.e., columns at index 8, 9, 10) to datetime.date\n",
    "    for col in df.columns[8:11]:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce').dt.date\n",
    "\n",
    "    # Create new column: expected delivery date = ETA-Last CY/CFS Location + 5 days\n",
    "    df['expected delivery date'] = pd.to_datetime(df['ETA-Last CY/CFS Location'], errors='coerce') + pd.Timedelta(days=5)\n",
    "\n",
    "    # Move 'expected delivery date' to column index 10\n",
    "    df.insert(10, 'expected delivery date', df.pop('expected delivery date'))\n",
    "\n",
    "    return df\n",
    "\n",
    "# Soma Data Cleaning\n",
    "def clean_soma(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Drop unwanted columns\n",
    "    df = df.drop(columns=[\"SCAC CODE\", \"AN STATUS\"])\n",
    "\n",
    "    # Fix Master Bill of Lading\n",
    "    prefix_to_scac = {\n",
    "        'BOM': 'HDMU',\n",
    "        'MUM': 'ONEY',\n",
    "        'BO': 'HLCU',\n",
    "        '067': 'WHLC',\n",
    "        '639': 'COSU',\n",
    "    }\n",
    "    sorted_prefixes = sorted(prefix_to_scac.keys(), key=lambda x: len(x), reverse=True)\n",
    "\n",
    "    def update_mbl(row):\n",
    "        for prefix in sorted_prefixes:\n",
    "            if isinstance(row, str) and row.startswith(prefix):\n",
    "                return prefix_to_scac[prefix] + row\n",
    "        return row\n",
    "\n",
    "    df['Master Bill of Lading'] = df['Master Bill of Lading'].apply(update_mbl)\n",
    "\n",
    "    # Format specific columns as dates\n",
    "    for col in df.columns[8:15]:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce').dt.date\n",
    "\n",
    "    return df\n",
    "\n",
    "# Tanera Go Data Cleaning\n",
    "def clean_tanerago(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Format specific columns as dates\n",
    "    for col in df.columns[15:29]:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce').dt.date\n",
    "    return df\n",
    "\n",
    "# Opening Template and Pasting Dataframes\n",
    "def load_template_and_paste_data(\n",
    "    prefix: str = \"Inbound Weekly Update Template\",\n",
    "    sheets_data: Dict[str, pd.DataFrame] = None\n",
    ") -> None:\n",
    "    file_pattern = f\"{prefix}*.xlsm\"\n",
    "    matching_files = glob.glob(file_pattern)\n",
    "\n",
    "    if not matching_files:\n",
    "        print(f\"No matching files found for prefix: {prefix}\")\n",
    "        return\n",
    "\n",
    "    file_to_load = matching_files[0]\n",
    "    app = xw.App(visible=False)\n",
    "    wb = app.books.open(file_to_load)\n",
    "    print(f\"Loaded workbook: {file_to_load}\")\n",
    "\n",
    "    # Close extra open workbooks\n",
    "    for book in app.books:\n",
    "        if book.name != wb.name:\n",
    "            print(f\"Closing extra workbook: {book.name}\")\n",
    "            book.close()\n",
    "\n",
    "    # Paste each DataFrame into its corresponding sheet at A2\n",
    "# Paste each DataFrame into its corresponding sheet at A2\n",
    "    if sheets_data:\n",
    "        for sheet_name, df in sheets_data.items():\n",
    "            if df is None:\n",
    "                print(f\"Warning: DataFrame for '{sheet_name}' is None, skipping.\")\n",
    "                continue\n",
    "            try:\n",
    "                sheet = wb.sheets[sheet_name]\n",
    "                sheet.range(\"A2\").value = df.values\n",
    "                print(f\"Pasted data into sheet: {sheet_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error pasting into sheet '{sheet_name}': {e}\")\n",
    "\n",
    "    # Save workbook into today's folder under ~/Documents/Reports/\n",
    "    today = datetime.today()\n",
    "    today_str = today.strftime(\"%m.%d.%y\")\n",
    "    folder_name = today.strftime(\"%m.%d.%y\")\n",
    "    reports_dir = os.path.expanduser(f\"~/OneDrive - Prime Time Packaging/Inbound Update\")\n",
    "\n",
    "    # Create the folder if it doesn't exist\n",
    "    os.makedirs(reports_dir, exist_ok=True)\n",
    "\n",
    "    new_filename = f\"Inbound Weekly Update Template LMH {today_str}.xlsm\"\n",
    "    new_filepath = os.path.join(reports_dir, new_filename)\n",
    "    wb.save(new_filepath)\n",
    "    print(f\"Workbook saved as: {new_filename} in {reports_dir}\")\n",
    "\n",
    "    # Close workbook and quit Excel\n",
    "    wb.close()\n",
    "    print(\"Workbook closed.\")\n",
    "    app.quit()\n",
    "    print(\"Excel app quit.\")\n",
    "\n",
    "\n",
    "# File Configs and variables\n",
    "\n",
    "file_configs = {\n",
    "    \"ERP\": {\n",
    "        \"prefix\": \"InboundShipments\",\n",
    "        \"extension\": \"csv\",\n",
    "        \"loader\": pd.read_csv,\n",
    "        \"kwargs\": {}\n",
    "    },\n",
    "    \"Topocean\": {\n",
    "        \"prefix\": \"PRIME TIME PACKAGING\",\n",
    "        \"extension\": \"xls\",\n",
    "        \"loader\": pd.read_excel,\n",
    "        \"kwargs\": {\"engine\": \"xlrd\", \"skiprows\": 7}\n",
    "    },\n",
    "    \"OEC_Email\": {\n",
    "        \"prefix\": \"OEC GROUP Container Tracking Report\",\n",
    "        \"extension\": \"xlsx\",\n",
    "        \"loader\": pd.read_excel,\n",
    "        \"kwargs\": {\"skiprows\": 6},\n",
    "        \"postprocess\": lambda df: df.drop(columns=[\"Unnamed: 0\", \"Unnamed: 1\"], errors=\"ignore\")\n",
    "    },\n",
    "    \"OEC_Portal\": {\n",
    "        \"prefix\": \"OEC2 Upload\",\n",
    "        \"extensions\": [(\"xlsx\", pd.read_excel), (\"csv\", pd.read_csv)],\n",
    "        \"loader\": pd.read_excel,\n",
    "        \"kwargs\": {},\n",
    "        \"postprocess\": clean_oec_portal \n",
    "    },\n",
    "    \"Soma\": {\n",
    "        \"prefix\": \"PTP SOMA\",\n",
    "        \"extension\": \"xlsx\",\n",
    "        \"loader\": pd.read_excel,\n",
    "        \"kwargs\": {\"skiprows\": [1]},\n",
    "        \"postprocess\": clean_soma\n",
    "    },\n",
    "    \"TaneraGo\": {\n",
    "        \"prefix\": \"Shipment_status\",\n",
    "        \"extension\": \"xlsx\",\n",
    "        \"loader\": pd.read_excel,\n",
    "        \"kwargs\": {},\n",
    "        \"postprocess\": clean_tanerago\n",
    "    },\n",
    "    \"Harbour\": {\n",
    "        \"prefix\": \"Forwarder Inbound Template\",\n",
    "        \"extension\": \"xlsx\",\n",
    "        \"loader\": pd.read_excel,\n",
    "        \"kwargs\": {}\n",
    "    },\n",
    "    \"Idc\": {\n",
    "        \"prefix\": \"PRIME TIME DSR\",\n",
    "        \"extensions\": [(\"xlsx\", pd.read_excel), (\"csv\", pd.read_csv)],\n",
    "        \"loader\": pd.read_excel,\n",
    "        \"kwargs\": {}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define base directory\n",
    "base_dir = os.path.expanduser(\"~/OneDrive - Prime Time Packaging/Inbound Update\")\n",
    "prefixes = [cfg[\"prefix\"] for cfg in file_configs.values()]\n",
    "latest_folders = get_latest_folders(base_dir, prefixes)\n",
    "\n",
    "# Data Cleaning Code Execution\n",
    "start_time = time.time()\n",
    "# Data Cleaning Code Execution\n",
    "for config_name, config in file_configs.items():\n",
    "    prefix = config[\"prefix\"]\n",
    "    folder_path = latest_folders.get(prefix)\n",
    "\n",
    "    if not folder_path:\n",
    "        print(f\"No folder found for prefix '{prefix}'\")\n",
    "        continue\n",
    "\n",
    "    df = load_file_from_config(config, folder_path)\n",
    "\n",
    "    if df is not None:\n",
    "        globals()[f\"{config_name}_df\"] = df\n",
    "        print(f\"Loaded {config_name} file successfully!\")\n",
    "    else:\n",
    "        print(f\"Failed to load {config_name} file.\")\n",
    "\n",
    "\n",
    "\n",
    "# Dictionary mapping each DataFrame to its corresponding sheet name\n",
    "sheets_data = {\n",
    "    'ERP': ERP_df,\n",
    "    'topocean': Topocean_df,\n",
    "    'OEC Portal': OEC_Portal_df,\n",
    "    'OEC Email': OEC_Email_df,\n",
    "    'Soma': Soma_df,\n",
    "    'Tanera Go': TaneraGo_df,\n",
    "    'Harbour': Harbour_df,\n",
    "    'IDC': Idc_df  \n",
    "}\n",
    "\n",
    "# Call the function \n",
    "load_template_and_paste_data(sheets_data=sheets_data)\n",
    "\n",
    "# <<< Place timing code here, after everything else >>>\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nScript executed in {elapsed_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdfc129-9607-46c3-bd2a-4ac991389690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
